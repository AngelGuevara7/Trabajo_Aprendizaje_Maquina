{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4b7a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "144dbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos\n",
    "\n",
    "X=np.load(\"./datos_mfcc_pca99_X.npy\")\n",
    "y=np.load(\"./datos_mfcc_pca99_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dabfc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos el conjunto de entrenamiento al 50% usando un método no supervisado. En este caso, un C-means con el que pretendemos\n",
    "# quedarnos con los centros de los clusters que aparezcan, que serán los puntos más representativos.\n",
    "\n",
    "c = 6             # número de clases\n",
    "nc = 120          # muestras por clase\n",
    "n= 720           # número de muestras totales\n",
    "\n",
    "X_reduc=[]\n",
    "y_reduc=np.int16(np.kron(np.arange(c),np.ones(nc//2)))\n",
    "\n",
    "for i in range(0,n,nc):\n",
    "    k_means=KMeans(n_clusters=nc//2, random_state=0)\n",
    "    k_means.fit(X[i:(i+nc)])\n",
    "    centros=k_means.cluster_centers_\n",
    "    X_reduc.append(centros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abb817e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 464)\n",
      "(360, 464)\n"
     ]
    }
   ],
   "source": [
    "print(X_reduc[0].shape)\n",
    "# Reshapeamos las dimensiones de X_reduc para tenerlo todo en una matriz dónde cada fila será una muestra y cada columna una \n",
    "# característica. La matriz estará ordenada por clases. \n",
    "# Para reshapear, antes habrá que convertir a array.\n",
    "\n",
    "\n",
    "X_reduc=np.array(X_reduc).reshape((360,464))\n",
    "print(X_reduc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3be1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ya podemos dividir nuestro conjunto reducido en entrenamiento y test, y probar algunos métodos Kernel.\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X_reduc, y_reduc, test_size=0.3, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f20137b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "OA train 0.91\n",
      "Kappa train 0.89\n",
      "OA test 0.73\n",
      "Kappa test 0.68\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos directamente un clasificador SVC con los parámetros por defecto y calculamos algunas métricas para ver cómo funciona\n",
    "\n",
    "clf=svm.SVC(verbose=True)\n",
    "clf.fit(Xtr,ytr)\n",
    "\n",
    "score_tr = clf.score(Xtr,ytr)\n",
    "score_ts = clf.score(Xts,yts)\n",
    "preds_train=clf.predict(Xtr)\n",
    "preds_test = clf.predict(Xts)\n",
    "\n",
    "print('')\n",
    "print('OA train %0.2f' % score_tr)\n",
    "print('Kappa train %0.2f' % metrics.cohen_kappa_score(ytr,preds_train))\n",
    "print('OA test %0.2f' % score_ts)\n",
    "print('Kappa test %0.2f' % metrics.cohen_kappa_score(yts,preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f426d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0  5  0  1  3]\n",
      " [ 2 13  0  2  0  3]\n",
      " [ 1  0 14  4  0  1]\n",
      " [ 2  0  1 19  0  0]\n",
      " [ 0  0  2  0 15  1]\n",
      " [ 0  0  0  0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "\n",
    "CM=metrics.confusion_matrix(yts,preds_test)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858506ae",
   "metadata": {},
   "source": [
    "Observamos que con los parámetros por defecto, obtenemos unos resultados bastante buenos en entrenamiento y un acierto bastante decente en test. \n",
    "\n",
    "Además, vemos que la matriz de confusión está bastante balanceada, por lo que tiene buena pinta este clasificador para nuestros datos.\n",
    "\n",
    "Veamos ahora qué ocurre si hacemos una búsqueda por cross-validation de los parámetros ideales. Queremos intentar mejorar lo que ya tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99c33ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los parámetros por defecto usados han sido \n",
    "\n",
    "clf.get_params() \n",
    "\n",
    "# dónde gamma= 'scale' viene definida por la siguiente fórmula: gamma = 1/(464*Xtr.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2abaf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.001214252382119e-06"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(464*Xtr.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef65a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OA train 0.98\n",
      "Kappa train 0.98\n",
      "OA test 0.75\n",
      "Kappa test 0.70\n"
     ]
    }
   ],
   "source": [
    "# Buscamos los parámetros óptimos con GridSearchCV\n",
    "\n",
    "gammas = np.logspace(-8, 8, 10)\n",
    "Cs = np.logspace(-6, 6, 10)  \n",
    "tuned_parameters = { 'gamma': gammas,'C': Cs} \n",
    "\n",
    "clf2 = GridSearchCV(svm.SVC(kernel='rbf'), tuned_parameters, cv=5,n_jobs=-1,verbose=0)\n",
    "clf2.fit(Xtr,ytr)\n",
    "clf2=clf2.best_estimator_\n",
    "\n",
    "score_tr = clf2.score(Xtr,ytr)\n",
    "score_ts = clf2.score(Xts,yts)\n",
    "preds_train=clf2.predict(Xtr)\n",
    "preds_test = clf2.predict(Xts)\n",
    "\n",
    "print('')\n",
    "print('OA train %0.2f' % score_tr)\n",
    "print('Kappa train %0.2f' % metrics.cohen_kappa_score(ytr,preds_train))\n",
    "print('OA test %0.2f' % score_ts)\n",
    "print('Kappa test %0.2f' % metrics.cohen_kappa_score(yts,preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "646233dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, gamma=5.994842503189409e-07)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb2ff2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 5.994842503189409e-07,\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44d08390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  2  1  0  0  2]\n",
      " [ 4 13  1  1  0  1]\n",
      " [ 1  0 14  4  0  1]\n",
      " [ 3  0  1 18  0  0]\n",
      " [ 0  0  0  0 17  1]\n",
      " [ 0  1  2  0  1  7]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "\n",
    "CM=metrics.confusion_matrix(yts,preds_test)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3c8a4",
   "metadata": {},
   "source": [
    "En general, vemos como al buscar los parámetros óptimos de la función Kernel (='rbf'), los resultados mejoran en todos los aspectos. Obtenemos un mayor acierto tanto en entrenamiento como en test y están balanceados, por lo que en principio no sospecharíamos de sobreajuste. \n",
    "\n",
    "Además, al ver la forma de la matriz de confusión volvemos a ver lo mismo, los resultados están muy balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86369687",
   "metadata": {},
   "source": [
    "Ahora vamos a probar a usar el conjunto que hemos obtenido tras eliminar algunas características que no tienen demasiada importancia. Dicho conjunto lo hemos obtenido en el notebook de Árboles. \n",
    "\n",
    "Lo cargamos y vemos si mejoran los resultados, o si simplemente no empeoran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd6a3c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduc2=np.load(\"./datos_mfcc_pca99_X_reducido_2kmeans.npy\")\n",
    "y_reduc=np.load(\"./datos_mfcc_pca99_y_reducido_kmeans.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3750cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c94a424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reduc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72a78666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ya podemos dividir nuestro conjunto reducido en entrenamiento y test, y probar algunos métodos Kernel.\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X_reduc2, y_reduc, test_size=0.3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bebb4a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OA train 0.81\n",
      "Kappa train 0.78\n",
      "OA test 0.69\n",
      "Kappa test 0.63\n"
     ]
    }
   ],
   "source": [
    "# Buscamos los parámetros óptimos con GridSearchCV\n",
    "\n",
    "gammas = np.logspace(-7, 7, 10)\n",
    "Cs = np.logspace(-2, 4, 10)  \n",
    "tuned_parameters = { 'gamma': gammas,'C': Cs} \n",
    "\n",
    "clf2 = GridSearchCV(svm.SVC(kernel='rbf'), tuned_parameters, cv=5,n_jobs=-1,verbose=0)\n",
    "clf2.fit(Xtr,ytr)\n",
    "clf2=clf2.best_estimator_\n",
    "\n",
    "score_tr = clf2.score(Xtr,ytr)\n",
    "score_ts = clf2.score(Xts,yts)\n",
    "preds_train=clf2.predict(Xtr)\n",
    "preds_test = clf2.predict(Xts)\n",
    "\n",
    "print('')\n",
    "print('OA train %0.2f' % score_tr)\n",
    "print('Kappa train %0.2f' % metrics.cohen_kappa_score(ytr,preds_train))\n",
    "print('OA test %0.2f' % score_ts)\n",
    "print('Kappa test %0.2f' % metrics.cohen_kappa_score(yts,preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fcefd03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4.6415888336127775,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 3.5938136638046257e-06,\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1666cde4",
   "metadata": {},
   "source": [
    "Parece que empeoran los resultados. No sé si merece la pena si lo comparamos con la gran reducción de la dimensionalidad que hemos hecho.\n",
    "\n",
    "Aún así, siguen siendo mejores resultados que los que obtenemos usando clasificadores del tipo árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f2e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
