{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b77541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff20b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos solo con las características más importantes\n",
    "\n",
    "X_reduc2=np.load(\"./datos_mfcc_pca99_X_reducido2.npy\")\n",
    "y_reduc=np.load(\"./datos_mfcc_pca99_y_reducido.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2c8b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 44)\n"
     ]
    }
   ],
   "source": [
    "print(X_reduc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e95adbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "print(y_reduc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e65bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ya podemos dividir nuestro conjunto reducido en entrenamiento y test, y probar algunos métodos Kernel.\n",
    "X_reduc2= preprocessing.StandardScaler().fit_transform(X_reduc2) \n",
    "Xtr, Xts, ytr, yts = train_test_split(X_reduc2, y_reduc, test_size=0.3, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85fb86b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53        17\n",
      "           1       0.57      0.60      0.59        20\n",
      "           2       0.54      0.35      0.42        20\n",
      "           3       0.70      0.64      0.67        22\n",
      "           4       0.58      0.61      0.59        18\n",
      "           5       0.39      0.64      0.48        11\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.55      0.56      0.55       108\n",
      "weighted avg       0.57      0.56      0.55       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos un Random Forest con todos los parámetros por defecto.\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=8)   # Lo dejamos todo por defecto a ver qué tal funciona.\n",
    "rf.fit(Xtr,ytr)\n",
    "\n",
    "preds_test = rf.predict(Xts)\n",
    "print('Res Random Forest:', metrics.classification_report(yts, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "411fb027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA train 0.98\n",
      "OA test 0.56\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el acierto en entrenamiento y en test del árbol final con el que nos hemos quedado.\n",
    "\n",
    "print(\"OA train %0.2f\" %rf.score(Xtr, ytr))\n",
    "print(\"OA test %0.2f\" %rf.score(Xts, yts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4ba95b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56e7ae",
   "metadata": {},
   "source": [
    "Vemos que mejoramos los resultados, pero solamente un poco. Probamos a cambiar los parámetros y añadir más árboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0316bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.41      0.47        17\n",
      "           1       0.70      0.70      0.70        20\n",
      "           2       0.67      0.60      0.63        20\n",
      "           3       0.80      0.73      0.76        22\n",
      "           4       0.65      0.61      0.63        18\n",
      "           5       0.35      0.64      0.45        11\n",
      "\n",
      "    accuracy                           0.62       108\n",
      "   macro avg       0.62      0.61      0.61       108\n",
      "weighted avg       0.64      0.62      0.63       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos un Random Forest cambiando los parámetros por defecto.\n",
    "\n",
    "T=10000  # Número de árboles\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=T, max_depth=8)   \n",
    "rf2.fit(Xtr,ytr)\n",
    "\n",
    "preds_test2 = rf2.predict(Xts)\n",
    "print('Res Random Forest:', metrics.classification_report(yts, preds_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17a213b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA train 0.99\n",
      "OA test 0.62\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el acierto en entrenamiento y en test del árbol final con el que nos hemos quedado.\n",
    "\n",
    "print(\"OA train %0.2f\" %rf2.score(Xtr, ytr))\n",
    "print(\"OA test %0.2f\" %rf2.score(Xts, yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570483e",
   "metadata": {},
   "source": [
    "Parece que mejoramos algo más el rendimiento con el Random Forest que con el bagging simplemente. En entrenamiento tenemos muy buenos resultados y en test hemos avanzado un poco más."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a7c70",
   "metadata": {},
   "source": [
    "Podemos probar cambiando el criterio de decisión. El que viene por defecto es el de la impureza de Gini. Probamos con el de la entropía para ver si mejoran los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bdbe0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.41      0.48        17\n",
      "           1       0.69      0.55      0.61        20\n",
      "           2       0.57      0.40      0.47        20\n",
      "           3       0.73      0.73      0.73        22\n",
      "           4       0.53      0.56      0.54        18\n",
      "           5       0.32      0.73      0.44        11\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.57      0.56      0.55       108\n",
      "weighted avg       0.59      0.56      0.56       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos un Random Forest cambiando los parámetros por defecto.\n",
    "\n",
    "T=10000  # Número de árboles\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=T, max_depth=6, criterion='entropy')   \n",
    "rf3.fit(Xtr,ytr)\n",
    "\n",
    "preds_test3 = rf3.predict(Xts)\n",
    "print('Res Random Forest:', metrics.classification_report(yts, preds_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a521adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA train 0.92\n",
      "OA test 0.56\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el acierto en entrenamiento y en test del árbol final con el que nos hemos quedado.\n",
    "\n",
    "print(\"OA train %0.2f\" %rf3.score(Xtr, ytr))\n",
    "print(\"OA test %0.2f\" %rf3.score(Xts, yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edd616",
   "metadata": {},
   "source": [
    "En este caso parece que el mejor criterio a la hora de decidir por qué característica hacer la división, es el de la impureza de Gini ya que nos da mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829425fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
