{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "157ecee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "926870fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos solo con las características más importantes\n",
    "\n",
    "X_reduc2=np.load(\"./datos_mfcc_pca99_X_reducido2.npy\")\n",
    "y_reduc=np.load(\"./datos_mfcc_pca99_y_reducido.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1214bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 44)\n"
     ]
    }
   ],
   "source": [
    "print(X_reduc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62f0d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ya podemos dividir nuestro conjunto reducido en entrenamiento y test, y probar algunos métodos Kernel.\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X_reduc2, y_reduc, test_size=0.3, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03ee125e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res bagging_trees:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.35      0.33        17\n",
      "           1       0.33      0.25      0.29        20\n",
      "           2       0.63      0.60      0.62        20\n",
      "           3       0.81      0.59      0.68        22\n",
      "           4       0.56      0.56      0.56        18\n",
      "           5       0.19      0.36      0.25        11\n",
      "\n",
      "    accuracy                           0.46       108\n",
      "   macro avg       0.47      0.45      0.45       108\n",
      "weighted avg       0.51      0.46      0.48       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intentamos hacer bagging con árboles de decisión. Lo intentamos primero con los parámetros por defecto. \n",
    "# Por defecto, la implementación de bagging para problemas de clasificación usa árboles de decisión. Sin embargo, vamos a usar\n",
    "# los árboles con los parámetros adecuados que ya habíamos calculado en el notebook de Árboles.\n",
    "\n",
    "arbol = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=0)\n",
    "\n",
    "bagging_trees = BaggingClassifier(base_estimator=arbol, random_state=0)\n",
    "bagging_trees.fit(Xtr,ytr)\n",
    "\n",
    "preds_test = bagging_trees.predict(Xts)\n",
    "print('Res bagging_trees:', metrics.classification_report(yts, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "74c02b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA train 0.76\n",
      "OA test 0.46\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el acierto en entrenamiento y en test del árbol final con el que nos hemos quedado.\n",
    "\n",
    "print(\"OA train %0.2f\" %bagging_trees.score(Xtr, ytr))\n",
    "print(\"OA test %0.2f\" %bagging_trees.score(Xts, yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44733bae",
   "metadata": {},
   "source": [
    "Observamos que esta predicción ya mejora un pelín respecto a la obteníamos con un sólo árbol, pero tampoco demasiado. \n",
    "En test solo hemos mejorado un 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2404f42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__ccp_alpha': 0.0,\n",
       " 'base_estimator__class_weight': None,\n",
       " 'base_estimator__criterion': 'entropy',\n",
       " 'base_estimator__max_depth': 4,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_impurity_decrease': 0.0,\n",
       " 'base_estimator__min_impurity_split': None,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__random_state': 0,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'base_estimator': DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=0),\n",
       " 'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veamos cuáles son los parámetros por defecto. Quizás hemos agregado pocos árboles ya que el rendimiento no es muy bueno.\n",
    "\n",
    "bagging_trees.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35199a4",
   "metadata": {},
   "source": [
    "En efecto, vemos como solo hemos combinado 10 árboles de decisión. Quizás son muy pocos. Probamos a cambiar dicho parámetro (`n_estimators`) para ver si mejora la cosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3c30968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res bagging_trees:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.35      0.35        17\n",
      "           1       0.43      0.45      0.44        20\n",
      "           2       0.60      0.60      0.60        20\n",
      "           3       0.79      0.50      0.61        22\n",
      "           4       0.58      0.61      0.59        18\n",
      "           5       0.41      0.64      0.50        11\n",
      "\n",
      "    accuracy                           0.52       108\n",
      "   macro avg       0.53      0.53      0.52       108\n",
      "weighted avg       0.54      0.52      0.52       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intentamos hacer bagging con árboles de decisión. Lo intentamos cambiando los parámetros por defecto. \n",
    "\n",
    "T=1000\n",
    "\n",
    "bagging_trees2 = BaggingClassifier(base_estimator=arbol,n_estimators=T,random_state=0)\n",
    "bagging_trees2.fit(Xtr,ytr)\n",
    "\n",
    "preds_test2 = bagging_trees2.predict(Xts)\n",
    "print('Res bagging_trees:', metrics.classification_report(yts, preds_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c2c8772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA train 0.83\n",
      "OA test 0.52\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el acierto en entrenamiento y en test del árbol final con el que nos hemos quedado.\n",
    "\n",
    "print(\"OA train %0.2f\" % bagging_trees2.score(Xtr, ytr))\n",
    "print(\"OA test %0.2f\" % bagging_trees2.score(Xts, yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6252c6",
   "metadata": {},
   "source": [
    "Obsevarmos que al agregar 1000 árboles de decisión, los resultados en entrenamiento y test mejoran un poco (más en entrenamiento que en test en proporción). Sin embargo, el acierto en test que es el que nos interesa más, no ha subido gran cosa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196a437",
   "metadata": {},
   "source": [
    "Intenamos hacer bagging con clasificadores del tipo SVC para ver si mejora el rendimiento. Usaremos el clasificador con los parámetros óptimos que ya calculamos en el notebook de SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "45b8129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res bagging_svc:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.35      0.44        17\n",
      "           1       0.63      0.60      0.62        20\n",
      "           2       0.69      0.45      0.55        20\n",
      "           3       0.67      0.73      0.70        22\n",
      "           4       0.62      0.56      0.59        18\n",
      "           5       0.31      0.73      0.43        11\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.59      0.57      0.55       108\n",
      "weighted avg       0.61      0.56      0.57       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos el clasificador con el que queremos hacer bagging.\n",
    "\n",
    "svc = svm.SVC(C=4.6415888336127775, gamma=3.5938136638046257e-06)\n",
    "\n",
    "N=500\n",
    "\n",
    "bagging_svc = BaggingClassifier(base_estimator=svc,n_estimators=N,random_state=0)\n",
    "bagging_svc.fit(Xtr,ytr)\n",
    "\n",
    "preds_test3 = bagging_svc.predict(Xts)\n",
    "print('Res bagging_svc:', metrics.classification_report(yts, preds_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a1f00f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA train 0.71\n",
      "OA test 0.56\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el acierto en entrenamiento y en test del árbol final con el que nos hemos quedado.\n",
    "\n",
    "print(\"OA train %0.2f\" % bagging_svc.score(Xtr, ytr))\n",
    "print(\"OA test %0.2f\" % bagging_svc.score(Xts, yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd28a86",
   "metadata": {},
   "source": [
    "Vemos como no han mejorado los aciertos respecto a usar un solo clasificador el tipo SVC. No merece la pena hacer bagging con máquinas de vectores soporte. Esto se puede deber a que sean un método más estable, y con métodos estables no funciona muy bien el bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac4f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
